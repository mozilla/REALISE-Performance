*Files definitions*
This repository contains the code to extract performance-related data as well as the data itself.
The code files are as follows :
- `extract-alerts.py` : extracts performance-related alerts (ones triggered from one year ago until the time of running the script) using an API endpoint. It produces two data files `alerts_data.csv` and `signatures.txt`.
- `extract-bugs.py` : extracts all bugs by using [bugbug](https://github.com/mozilla/bugbug) and labels bugs between performance-related and not performance-related. It produces a data file `bugs_data.csv`.
- `extract-timeseries.py` : given `signatures.txt` which contains signature IDs associated with performance-related alerts triggered in the last year, signatures timeseries are extracted using a combination of API endpoints. It produces multiple folders, each representing signature IDs from a specific project. Each folder contains files each representing the timeseries associated with one signature ID.
- `transform-data.py` : given the folders generated through running `extract-timeseries.py`, the script goes through the files and labels the entries in them as follows : 
  - True negatives : timeseries data points that are not appearing in the alerts whatsoever
  - False positives : timeseries data points that are associated with possible alerts that were investigated by the performance sheriffing team and were determined to be as not real alerts. In the alerts dataset, they have `alert_status` field as `invalid` or `wontfix`.
  - True positives : timeseries data points that are associated with possible alerts that were investigated by the performance sheriffing team and were determined to be as real alerts. In the alerts dataset, they have `alert_status` field as `improvement`, `backedout` or `fixed`.
  - Still processing : timeseries data points that are associated with possible alerts that are being investigated by the performance sheriffing team and are still to be determined if they are real alerts or not. In the alerts dataset, they have `alert_status` field as `investigating`, `reassigned` or `untriaged`.
The script will generate folders such as the ones generated by `extract-timeseries.py` but they are suffixed with `-processed`. Each folder contains labeled files each representing the timeseries associated with one signature ID.
*Running scripts*
0. In order to run the scripts, make sure to have Python 3.12 or above as well as pip in the running environment (Python 3.12.2 was used during scripts development). Afterwards, make sure to run : 
```
pip install -r requirements.txt
```
1. In order to run the script to extract the alerts, run : 
```
python extract-alerts.py
```
It will generate `alerts_data.csv` which will have the performance alerts data from the time of running the script all the waty back to one year before that. It will also generate `signatures.txt` which is needed by to extract timeseries data.
2. In order to run the script to extract the alerts, run : 
```
python extract-bugs.py
```
It will generate `bugs_data.csv` which will have all the bugs labeled if they're performance bugs or not.
3. In order to run the script to extract the timeseries data, make sure to have `signatures.txt`, then run : 
```
python extract-timseries.py
```
Note that for the case of autoland, timeseries files were divided across multiple folders because github does not support pushing a folder with more than 1000 files in them.
4. In order to run the script to extract the alerts, run : 
```
python transform-data.py
```
Note that the scripts contains the folders mapping to projects because autoland has 4 associated folders as mentionned earlier.